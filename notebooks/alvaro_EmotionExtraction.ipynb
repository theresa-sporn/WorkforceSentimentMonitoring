{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "from WorkforceSentimentMonitoring.data import get_data, merge, holdout, drop_wrong_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying entries in other languages...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [07:24<00:00, 44.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop 437 entries? [y] / n\n",
      "\n",
      "Dropping 437 entries...\n"
     ]
    }
   ],
   "source": [
    "submission, train, test = get_data()\n",
    "df = merge(submission, train, test)\n",
    "df = drop_wrong_language(df, 'review')\n",
    "target = [\n",
    "    \"work-balance\",\n",
    "    \"culture-values\",\n",
    "    \"career-opportunities\",\n",
    "    \"comp-benefits\",\n",
    "    \"senior-mgmt\",\n",
    "    \"overall\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Moving at the speed of light, burn out is inevitable 1) Food, food, food. 15+ cafes on main campus (MTV) alone. Mini-kitchens, snacks, drinks, free breakfast/lunch/dinner, all day, errr\\'day.  2) Benefits/perks. Free 24:7 gym access (on MTV campus). Free (self service) laundry (washer/dryer) available. Bowling alley. Volley ball pit. Custom-built and exclusive employee use only outdoor sport park (MTV). Free health/fitness assessments. Dog-friendly. Etc. etc. etc.  3) Compensation. In ~2010 or 2011, Google updated its compensation packages so that they were more competitive.  4) For the size of the organization (30K+), it has remained relatively innovative, nimble, and fast-paced and open with communication but, that is definitely changing (for the worse).  5) With so many departments, focus areas, and products, *in theory*, you should have plenty of opportunity to grow your career (horizontally or vertically). In practice, not true.  6) You get to work with some of the brightest, most innovative and hard-working/diligent minds in the industry. There\\'s a \"con\" to that, too (see below). 1) Work/life balance. What balance? All those perks and benefits are an illusion. They keep you at work and they help you to be more productive. I\\'ve never met anybody at Google who actually time off on weekends or on vacations. You may not hear management say, \"You have to work on weekends/vacations\" but, they set the culture by doing so - and it inevitably trickles down. I don\\'t know if Google inadvertently hires the work-a-holics or if they create work-a-holics in us. Regardless, I have seen way too many of the following: marriages fall apart, colleagues choosing work and projects over family, colleagues getting physically sick and ill because of stress, colleagues crying while at work because of the stress, colleagues shooting out emails at midnight, 1am, 2am, 3am. It is absolutely ridiculous and something needs to change.  2) Poor management. I think the issue is that, a majority of people love Google because they get to work on interesting technical problems - and these are the people that see little value in learning how to develop emotional intelligence. Perhaps they enjoy technical problems because people are too \"difficult.\" People are promoted into management positions - not because they actually know how to lead/manage, but because they happen to be smart or because there is no other path to grow into. So there is a layer of intelligent individuals who are horrible managers and leaders. Yet, there is no value system to actually do anything about that because \"emotional intelligence\" or \"adaptive leadership\" are not taken seriously.  3) Jerks. Sure, there are a lot of brilliant people - but, sadly, there are also a lot of jerks (and, many times, they are one and the same). Years ago, that wasn\\'t the case. I don\\'t know if the pool of candidates is getting smaller, or maybe all the folks with great personalities cashed out and left, or maybe people are getting burned out and it\\'s wearing on their personality and patience. I\\'ve heard stories of managers straight-up cussing out their employees and intimidating/scaring their employees into compliance.  4) It\\'s a giant company now and, inevitably, it has become slower moving and is now layered with process and bureaucracy. So many political battles, empire building, territory grabbing. Google says, \"Don\\'t be evil.\" But, that practice doesn\\'t seem to be put into place when it comes to internal practices. :( 1) Don\\'t dismiss emotional intelligence and adaptive leadership. They\\'re not just catch phases. You need great managers and leaders in order to build great companies and develop great employees. The people who may be brilliant at solving technical issues may not be (and are most often, not) the best candidates for management.  2) Do something about that work-ife balance. Don\\'t just have a bunch of pow-wows and tech talks and discussions about it. Leadership should actually model it. Consider re-evaluating how work is done, what processes are in place that are inefficient and ineffective and need to be updated or removed?  3) Don\\'t forget that there is already a pool of incredibly talented people within the company. If career development is really a goal at Google, then do it. Don\\'t just hire from the outside. Take the time to help your employees develop their careers - then maybe you won\\'t lose some of the great ones, and maybe you\\'ll have prevent some of that burn out and disillusionment.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text_series):\n",
    "    return text_series.apply(contractions.fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = expand_contractions(df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Moving at the speed of light, burn out is inevitable 1) Food, food, food. 15+ cafes on main campus (MTV) alone. Mini-kitchens, snacks, drinks, free breakfast/lunch/dinner, all day, errr\\'day.  2) Benefits/perks. Free 24:7 gym access (on MTV campus). Free (self service) laundry (washer/dryer) available. Bowling alley. Volley ball pit. Custom-built and exclusive employee use only outdoor sport park (MTV). Free health/fitness assessments. Dog-friendly. Etc. etc. etc.  3) Compensation. In ~2010 or 2011, Google updated its compensation packages so that they were more competitive.  4) For the size of the organization (30K+), it has remained relatively innovative, nimble, and fast-paced and open with communication but, that is definitely changing (for the worse).  5) With so many departments, focus areas, and products, *in theory*, you should have plenty of opportunity to grow your career (horizontally or vertically). In practice, not true.  6) You get to work with some of the brightest, most innovative and hard-working/diligent minds in the industry. there is a \"con\" to that, too (see below). 1) Work/life balance. What balance? All those perks and benefits are an illusion. They keep you at work and they help you to be more productive. I have never met anybody at Google who actually time off on weekends or on vacations. You may not hear management say, \"You have to work on weekends/vacations\" but, they set the culture by doing so - and it inevitably trickles down. I do not know if Google inadvertently hires the work-a-holics or if they create work-a-holics in us. Regardless, I have seen way too many of the following: marriages fall apart, colleagues choosing work and projects over family, colleagues getting physically sick and ill because of stress, colleagues crying while at work because of the stress, colleagues shooting out emails at midnight, 1am, 2am, 3am. It is absolutely ridiculous and something needs to change.  2) Poor management. I think the issue is that, a majority of people love Google because they get to work on interesting technical problems - and these are the people that see little value in learning how to develop emotional intelligence. Perhaps they enjoy technical problems because people are too \"difficult.\" People are promoted into management positions - not because they actually know how to lead/manage, but because they happen to be smart or because there is no other path to grow into. So there is a layer of intelligent individuals who are horrible managers and leaders. Yet, there is no value system to actually do anything about that because \"emotional intelligence\" or \"adaptive leadership\" are not taken seriously.  3) Jerks. Sure, there are a lot of brilliant people - but, sadly, there are also a lot of jerks (and, many times, they are one and the same). Years ago, that was not the case. I do not know if the pool of candidates is getting smaller, or maybe all the folks with great personalities cashed out and left, or maybe people are getting burned out and it is wearing on their personality and patience. I have heard stories of managers straight-up cussing out their employees and intimidating/scaring their employees into compliance.  4) it is a giant company now and, inevitably, it has become slower moving and is now layered with process and bureaucracy. So many political battles, empire building, territory grabbing. Google says, \"do not be evil.\" But, that practice does not seem to be put into place when it comes to internal practices. :( 1) do not dismiss emotional intelligence and adaptive leadership. they are not just catch phases. You need great managers and leaders in order to build great companies and develop great employees. The people who may be brilliant at solving technical issues may not be (and are most often, not) the best candidates for management.  2) Do something about that work-ife balance. do not just have a bunch of pow-wows and tech talks and discussions about it. Leadership should actually model it. Consider re-evaluating how work is done, what processes are in place that are inefficient and ineffective and need to be updated or removed?  3) do not forget that there is already a pool of incredibly talented people within the company. If career development is really a goal at Google, then do it. do not just hire from the outside. Take the time to help your employees develop their careers - then maybe you will not lose some of the great ones, and maybe you will have prevent some of that burn out and disillusionment.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = pd.DataFrame(df.review)\n",
    "y = df[target].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WorkforceSentimentMonitoring.encoders import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Company to work for People are smart and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Moving at the speed of light, burn out is inev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great balance between big-company security and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The best place I have worked and also the most...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Execellent for engineers Impact driven. Best t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52373</th>\n",
       "      <td>great place to grow! Great health benefits. Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52374</th>\n",
       "      <td>An ocean of opportunities diverse set of peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52375</th>\n",
       "      <td>Tech Gaint Equip its employees wid huge salari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52376</th>\n",
       "      <td>Terrible They had great health benefits (no lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52377</th>\n",
       "      <td>Microsoft is a good place to work Very structu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52378 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "0      Best Company to work for People are smart and ...\n",
       "1      Moving at the speed of light, burn out is inev...\n",
       "2      Great balance between big-company security and...\n",
       "3      The best place I have worked and also the most...\n",
       "4      Execellent for engineers Impact driven. Best t...\n",
       "...                                                  ...\n",
       "52373  great place to grow! Great health benefits. Ma...\n",
       "52374  An ocean of opportunities diverse set of peopl...\n",
       "52375  Tech Gaint Equip its employees wid huge salari...\n",
       "52376  Terrible They had great health benefits (no lo...\n",
       "52377  Microsoft is a good place to work Very structu...\n",
       "\n",
       "[52378 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best company work people smart friendly bureau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moving speed light burn inevitable food food f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great balance big company security fun fast mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best place worked also demanding find well reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>execellent engineer impact driven best tech wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52373</th>\n",
       "      <td>great place grow great health benefit many int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52374</th>\n",
       "      <td>ocean opportunity diverse set people problem s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52375</th>\n",
       "      <td>tech gaint equip employee wid huge salary high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52376</th>\n",
       "      <td>terrible great health benefit longer told many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52377</th>\n",
       "      <td>microsoft good place work structured organizat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52378 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "0      best company work people smart friendly bureau...\n",
       "1      moving speed light burn inevitable food food f...\n",
       "2      great balance big company security fun fast mo...\n",
       "3      best place worked also demanding find well reg...\n",
       "4      execellent engineer impact driven best tech wo...\n",
       "...                                                  ...\n",
       "52373  great place grow great health benefit many int...\n",
       "52374  ocean opportunity diverse set people problem s...\n",
       "52375  tech gaint equip employee wid huge salary high...\n",
       "52376  terrible great health benefit longer told many...\n",
       "52377  microsoft good place work structured organizat...\n",
       "\n",
       "[52378 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = Preprocessor()\n",
    "preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['review'] = X.review.str.replace('\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['review'] = X.review.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = pd.read_csv('../lexicon/EmotionIntensityLexicon.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness',\n",
       "       'surprise', 'trust'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon.emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion-intensity-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outraged</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brutality</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hatred</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hateful</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrorize</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9916</th>\n",
       "      <td>fugitive</td>\n",
       "      <td>trust</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917</th>\n",
       "      <td>divorce</td>\n",
       "      <td>trust</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918</th>\n",
       "      <td>mistakes</td>\n",
       "      <td>trust</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9919</th>\n",
       "      <td>bait</td>\n",
       "      <td>trust</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9920</th>\n",
       "      <td>scoundrel</td>\n",
       "      <td>trust</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9921 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word emotion  emotion-intensity-score\n",
       "0      outraged   anger                    0.964\n",
       "1     brutality   anger                    0.959\n",
       "2        hatred   anger                    0.953\n",
       "3       hateful   anger                    0.940\n",
       "4     terrorize   anger                    0.939\n",
       "...         ...     ...                      ...\n",
       "9916   fugitive   trust                    0.141\n",
       "9917    divorce   trust                    0.133\n",
       "9918   mistakes   trust                    0.133\n",
       "9919       bait   trust                    0.133\n",
       "9920  scoundrel   trust                    0.117\n",
       "\n",
       "[9921 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = X.review[1].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [word for word in tmp if word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WorkforceSentimentMonitoring.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.review = X.review.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['length'] = X.review.str.split(' ').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best company work people smart friendly bureau...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moving speed light burn inevitable food food f...</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great balance big company security fun fast mo...</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best place worked also demanding find well reg...</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>execellent engineer impact driven best tech wo...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  length\n",
       "0  best company work people smart friendly bureau...       9\n",
       "1  moving speed light burn inevitable food food f...     385\n",
       "2  great balance big company security fun fast mo...     436\n",
       "3  best place worked also demanding find well reg...     384\n",
       "4  execellent engineer impact driven best tech wo...      13"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion-intensity-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outraged</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brutality</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hatred</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hateful</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrorize</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word emotion  emotion-intensity-score\n",
       "0   outraged   anger                    0.964\n",
       "1  brutality   anger                    0.959\n",
       "2     hatred   anger                    0.953\n",
       "3    hateful   anger                    0.940\n",
       "4  terrorize   anger                    0.939"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>emotion</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaaaaaah</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaah</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abacus</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>0.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "emotion    anger  anticipation  disgust   fear  joy  sadness  surprise  trust\n",
       "word                                                                         \n",
       "aaaaaaah   0.000           0.0      0.0  0.344  0.0    0.000       0.0  0.000\n",
       "aaaah      0.000           0.0      0.0  0.234  0.0    0.000       0.0  0.000\n",
       "abacus     0.000           0.0      0.0  0.000  0.0    0.000       0.0  0.406\n",
       "abandon    0.000           0.0      0.0  0.531  0.0    0.703       0.0  0.000\n",
       "abandoned  0.222           0.0      0.0  0.534  0.0    0.828       0.0  0.000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.pivot_table(lexicon, values='emotion-intensity-score', index='word', columns='emotion', fill_value=0)\n",
    "\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_row = lexicon[(lexicon.word == 'hatred') & (lexicon.emotion == 'anger')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.953"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_row.iloc[0]['emotion-intensity-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion_score(row, lexicon, emotion):\n",
    "    review = row['review']\n",
    "    review_words = review.split(' ')\n",
    "    score = 0\n",
    "    for word in review_words:\n",
    "        select_row = lexicon[(lexicon.word == word) & (lexicon.emotion == emotion)]\n",
    "        if len(select_row) > 0:\n",
    "            score += select_row.iloc[0]['emotion-intensity-score']\n",
    "    return score / row['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = X.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = lexicon.emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness',\n",
       "       'surprise', 'trust'], dtype=object)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:40<00:00, 12.58s/it]\n"
     ]
    }
   ],
   "source": [
    "for emotion in tqdm(emotions):\n",
    "    tmp[f'{emotion}_score'] = tmp.apply(lambda x: get_emotion_score(x, lexicon, emotion), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['anger_score'] = tmp.apply(lambda x: get_emotion_score(x, lexicon, 'anger'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emotion_dictionary(lexicon):\n",
    "    \"\"\"Create dict with word : emo_array pairs\"\"\"\n",
    "    # create pivot table to better extract the word : array pairs\n",
    "    table = pd.pivot_table(lexicon, values='emotion-intensity-score',\n",
    "                           index='word', columns='emotion', fill_value=0)\n",
    "    # create dictionary\n",
    "    emo_scores_dict = {word : value for word , value in zip(table.index, table.values)}\n",
    "    return emo_scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordcount_vector(corpus):\n",
    "    \"\"\"Vectorize corpus. Corpus is a pd.Series with texts\"\"\"\n",
    "    vectorizer = CountVectorizer(stop_words='english', strip_accents='ascii')\n",
    "    X_vectorized = vectorizer.fit_transform(corpus)\n",
    "    X_vectorized = X_vectorized.toarray()\n",
    "    columns = vectorizer.get_feature_names()\n",
    "    X_vectorized = pd.DataFrame(X_vectorized, columns=columns)\n",
    "    return X_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_emotion_dict_and_wordcount(emo_scores_dict, word_count_vec):\n",
    "    \"\"\"Deletes the emotion keys in the dictionary that aren't present in the dataset\"\"\"\n",
    "    # Create set intersection with words appearing in both the dic and the vector\n",
    "    columns_intersection = set(word_count_vec.columns).intersection(set(emo_scores_dict.keys()))\n",
    "    # Drop unnecessary word columns in word_count_vec\n",
    "    word_count_vec = word_count_vec[columns_intersection]\n",
    "    # Drop innecessary entries in emo_scores_dict\n",
    "    keys_to_drop = set(emo_scores_dict.keys()).difference(columns_intersection)\n",
    "    for key in keys_to_drop:\n",
    "        emo_scores_dict.pop(key)\n",
    "    return emo_scores_dict, word_count_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_emotion_score(X, lexicon):\n",
    "    \"\"\"Extract emotion scores\"\"\"\n",
    "\n",
    "    X_vectorized = create_wordcount_vector(X['review'])\n",
    "    emo_scores_dict = create_emotion_dictionary(lexicon)\n",
    "    emo_scores_dict, X_vectorized = simplify_emotion_dict_and_wordcount(emo_scores_dict,\n",
    "                                                                        X_vectorized)\n",
    "    X['length'] = X.review.str.split(' ').apply(len)\n",
    "    emotions = lexicon.emotion.unique()\n",
    "\n",
    "    # Create new empty columns for emotion_scores\n",
    "    for emo in table.columns:\n",
    "        X[f'{emo}_score'] = np.nan\n",
    "    # iterate through every row\n",
    "    for i in tqdm(range(len(X))):\n",
    "        # select columns containing words in the word count vector\n",
    "        col_selector = X_vectorized.loc[i] > 0\n",
    "        review = X_vectorized.loc[i, col_selector]\n",
    "        # create an empty np.array with 8 spaces to add the results to\n",
    "        emo_score = np.zeros(8)\n",
    "        # iterate over the words contained in the review\n",
    "        for j in range(len(review)):\n",
    "            # select the word (string)\n",
    "            word = review.index[j]\n",
    "            # select the count (int)\n",
    "            word_count = review[j]\n",
    "            # compute emo_score by multiplying the array from the dict with the\n",
    "            # word count\n",
    "            emo_array = emo_scores_dict[word] * word_count\n",
    "            # add emo_array to emo_score array\n",
    "            emo_score += emo_array\n",
    "        # compute the average emo_array for the entire review\n",
    "        emo_score_avg = emo_score / X.length[i]\n",
    "        # iterate over the emotion columns to append the corresponding value\n",
    "        for idx, emo in enumerate(emotions):\n",
    "            X[f'{emo}_score'][i] = emo_score_avg[idx]\n",
    "\n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52378/52378 [01:33<00:00, 557.31it/s]\n"
     ]
    }
   ],
   "source": [
    "X = get_emotion_score(X, lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>anger_score</th>\n",
       "      <th>anticipation_score</th>\n",
       "      <th>disgust_score</th>\n",
       "      <th>fear_score</th>\n",
       "      <th>joy_score</th>\n",
       "      <th>sadness_score</th>\n",
       "      <th>surprise_score</th>\n",
       "      <th>trust_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6811</th>\n",
       "      <td>0.019149</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031550</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>0.014850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52314</th>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.018875</td>\n",
       "      <td>0.059917</td>\n",
       "      <td>0.016292</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.128250</td>\n",
       "      <td>0.017583</td>\n",
       "      <td>0.018250</td>\n",
       "      <td>0.134417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11789</th>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037333</td>\n",
       "      <td>0.091889</td>\n",
       "      <td>0.019944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12313</th>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42192</th>\n",
       "      <td>0.030319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018213</td>\n",
       "      <td>0.035852</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.007934</td>\n",
       "      <td>0.018951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         length  anger_score  anticipation_score  disgust_score  fear_score  \\\n",
       "6811   0.019149     0.046875            0.000000       0.030875    0.043750   \n",
       "52314  0.010638     0.018875            0.059917       0.016292    0.015625   \n",
       "11789  0.007447     0.000000            0.056833       0.000000    0.037333   \n",
       "12313  0.002660     0.000000            0.062444       0.000000    0.000000   \n",
       "42192  0.030319     0.000000            0.032770       0.000000    0.018213   \n",
       "\n",
       "       joy_score  sadness_score  surprise_score  trust_score  \n",
       "6811    0.000000       0.031550        0.005850     0.014850  \n",
       "52314   0.128250       0.017583        0.018250     0.134417  \n",
       "11789   0.091889       0.019944        0.000000     0.082056  \n",
       "12313   0.087556       0.000000        0.000000     0.000000  \n",
       "42192   0.035852       0.007180        0.007934     0.018951  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns='review')\n",
    "X_test = X_test.drop(columns='review')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train['length'] = scaler.fit_transform(X_train[['length']])\n",
    "X_test['length'] = scaler.transform(X_test[['length']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.316851215476645"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train['overall'])\n",
    "model.score(X_test, y_test['overall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_vector(corpus):\n",
    "    \"\"\"Vectorize corpus. Corpus is a pd.Series with texts\"\"\"\n",
    "    vectorizer = TfidfVectorizer(strip_accents='ascii')\n",
    "    X_vectorized = vectorizer.fit_transform(corpus)\n",
    "    X_vectorized = X_vectorized.toarray()\n",
    "    columns = vectorizer.get_feature_names()\n",
    "    X_vectorized = pd.DataFrame(X_vectorized, columns=columns)\n",
    "    return X_vectorized\n",
    "\n",
    "def get_emotion_score(X, lexicon):\n",
    "    \"\"\"Extract emotion scores\"\"\"\n",
    "\n",
    "    X_vectorized = create_tfidf_vector(X['review'])\n",
    "    emo_scores_dict = create_emotion_dictionary(lexicon)\n",
    "    emo_scores_dict, X_vectorized = simplify_emotion_dict_and_wordcount(emo_scores_dict,\n",
    "                                                                        X_vectorized)\n",
    "    X['length'] = X.review.str.split(' ').apply(len)\n",
    "    emotions = lexicon.emotion.unique()\n",
    "\n",
    "    # Create new empty columns for emotion_scores\n",
    "    for emo in table.columns:\n",
    "        X[f'{emo}_score'] = np.nan\n",
    "    # iterate through every row\n",
    "    for i in tqdm(range(len(X))):\n",
    "        # select columns containing words in the word count vector\n",
    "        col_selector = X_vectorized.loc[i] > 0\n",
    "        review = X_vectorized.loc[i, col_selector]\n",
    "        # create an empty np.array with 8 spaces to add the results to\n",
    "        emo_score = np.zeros(8)\n",
    "        # iterate over the words contained in the review\n",
    "        for j in range(len(review)):\n",
    "            # select the word (string)\n",
    "            word = review.index[j]\n",
    "            # select the count (int)\n",
    "            word_count = review[j]\n",
    "            # compute emo_score by multiplying the array from the dict with the\n",
    "            # word count\n",
    "            emo_array = emo_scores_dict[word] * word_count\n",
    "            # add emo_array to emo_score array\n",
    "            emo_score += emo_array\n",
    "        # iterate over the emotion columns to append the corresponding value\n",
    "        for idx, emo in enumerate(emotions):\n",
    "            X[f'{emo}_score'][i] = emo_score[idx]\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52378/52378 [01:38<00:00, 531.42it/s]\n"
     ]
    }
   ],
   "source": [
    "X = get_emotion_score(X, lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "scaler = MinMaxScaler()\n",
    "X_train['length'] = scaler.fit_transform(X_train[['length']])\n",
    "X_test['length'] = scaler.transform(X_test[['length']])\n",
    "X_train = X_train.drop(columns='review')\n",
    "X_test = X_test.drop(columns='review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3193967163039328"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train['overall'])\n",
    "model.score(X_test, y_test['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52378/52378 [01:37<00:00, 537.66it/s]\n"
     ]
    }
   ],
   "source": [
    "X = get_emotion_score(X, lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "scaler = MinMaxScaler()\n",
    "X_train['length'] = scaler.fit_transform(X_train[['length']])\n",
    "X_test['length'] = scaler.transform(X_test[['length']])\n",
    "X_train = X_train.drop(columns='review')\n",
    "X_test = X_test.drop(columns='review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32092401680030547"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train['overall'])\n",
    "model.score(X_test, y_test['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {1 : 0,\n",
    "           2 : 0,\n",
    "           3 : 1,\n",
    "           4 : 2,\n",
    "           5 : 2}\n",
    "y_three = y.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_three_train, y_three_test = train_test_split(X, y_three, test_size=0.3)\n",
    "scaler = MinMaxScaler()\n",
    "X_train['length'] = scaler.fit_transform(X_train[['length']])\n",
    "X_test['length'] = scaler.transform(X_test[['length']])\n",
    "X_train = X_train.drop(columns='review')\n",
    "X_test = X_test.drop(columns='review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5125365915743922"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_three_train['overall'])\n",
    "model.score(X_test, y_three_test['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {1 : 0,\n",
    "           2 : 0,\n",
    "           3 : 0,\n",
    "           4 : 1,\n",
    "           5 : 1}\n",
    "y_bin = y.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_bin_train, y_bin_test = train_test_split(X, y_bin, test_size=0.3)\n",
    "scaler = MinMaxScaler()\n",
    "X_train['length'] = scaler.fit_transform(X_train[['length']])\n",
    "X_test['length'] = scaler.transform(X_test[['length']])\n",
    "X_train = X_train.drop(columns='review')\n",
    "X_test = X_test.drop(columns='review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5771923125875016"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_bin_train['overall'])\n",
    "model.score(X_test, y_bin_test['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5785923380425099"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC()\n",
    "model.fit(X_train, y_bin_train['overall'])\n",
    "model.score(X_test, y_bin_test['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5736922489499809"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(class_weight='balanced', verbose=True, kernel='linear')\n",
    "model.fit(X_train, y_bin_train['overall'])\n",
    "model.score(X_test, y_bin_test['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.577637775232277"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(class_weight='balanced')\n",
    "model.fit(X_train, y_bin_train['overall'])\n",
    "model.score(X_test, y_bin_test['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': 'balanced',\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform, uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'C': loguniform(0.1, 1.0),\n",
    "        'break_ties': [False, True],\n",
    "        #'coef0': loguniform(0.0, 0.5),\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'shrinking': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': <scipy.stats._distn_infrastructure.rv_frozen at 0x1299ddcd0>,\n",
       " 'break_ties': [False, True],\n",
       " 'gamma': ['scale', 'auto'],\n",
       " 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
       " 'shrinking': [True, False]}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(class_weight='balanced')\n",
    "gridsearch = RandomizedSearchCV(model, grid,\n",
    "                                scoring=['f1', 'balanced_accuracy', 'f1_weighted'],\n",
    "                                cv=10, n_jobs=-1, verbose=1, refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 290.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=SVC(class_weight='balanced'), n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1299ddcd0>,\n",
       "                                        'break_ties': [False, True],\n",
       "                                        'gamma': ['scale', 'auto'],\n",
       "                                        'kernel': ['linear', 'poly', 'rbf',\n",
       "                                                   'sigmoid'],\n",
       "                                        'shrinking': [True, False]},\n",
       "                   refit=False,\n",
       "                   scoring=['f1', 'balanced_accuracy', 'f1_weighted'],\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.fit(X_train, y_bin_train['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
