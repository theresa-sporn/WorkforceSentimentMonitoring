{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data from package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WorkforceSentimentMonitoring.data import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WorkforceSentimentMonitoring.preprocessing import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../raw_data/train.csv\", nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID', 'Place', 'location', 'date', 'status', 'job_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.summary + ' ' + df.positives + ' ' + df.negatives\n",
    "\n",
    "df['text'] = text\n",
    "\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df.text).toarray()\n",
    "\n",
    "y = df.score_1.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X, y)\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../raw_data/train.csv\", nrows=100)\n",
    "\n",
    "df = df.drop(columns=['ID', 'Place', 'location', 'date', 'status', 'job_title', 'score_6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with na values in score cols\n",
    "score_cols = ['score_1', 'score_2', 'score_3', 'score_4', 'score_5', 'overall']\n",
    "df = df.dropna(axis=0, subset=score_cols)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast score cols as integers\n",
    "float_cols = df.select_dtypes(float).columns\n",
    "df[float_cols] = df[float_cols].astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['summary', 'positives', 'negatives', 'advice_to_mgmt']\n",
    "\n",
    "# combine all text columns\n",
    "df['text_combined'] = df[feature_cols].astype('U').agg(' '.join, axis=1)\n",
    "\n",
    "feature_cols.append('text_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df.text_combined).toarray()\n",
    "y = df.score_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X, y)\n",
    "# append predictions to df\n",
    "df['text_combined_score_1'] = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over features and append results to df as new cols\n",
    "\n",
    "result_scores = {}\n",
    "\n",
    "for feature in feature_cols:\n",
    "    scores_dic = {}\n",
    "    \n",
    "    for score in score_cols:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X = vectorizer.fit_transform(df[feature].astype('U'))\n",
    "        y = df[score]\n",
    "        model = MultinomialNB()\n",
    "        model.fit(X, y)\n",
    "        df[f'{feature}_{score}'] = model.predict(X)\n",
    "        scores_dic[f'{score}'] = model.score(X, y)\n",
    "        \n",
    "    result_scores[f'{feature}'] = scores_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over features and append results to df as new cols\n",
    "\n",
    "\n",
    "scores_dic = {}\n",
    "for score in score_cols:\n",
    "\n",
    "    result_scores = {}\n",
    "    for feature in feature_cols:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X = vectorizer.fit_transform(df[feature].astype('U'))\n",
    "        y = df[score]\n",
    "        model = MultinomialNB()\n",
    "        model.fit(X, y)\n",
    "        df[f'{feature}_{score}'] = model.predict(X)\n",
    "        result_scores[f'{feature}'] = model.score(X, y)\n",
    "        \n",
    "    scores_dic[f'{score}'] = result_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores_dic).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise prediction capability of every text slice\n",
    "\n",
    "fig = plt.figure(figsize=(8, 7))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "scores_df.plot(kind='bar', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get the subjectivity\n",
    "def getSubjectivity(text):\n",
    "  return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# Create a function to get the polarity\n",
    "def getPolarity(text):\n",
    "  return TextBlob(text).sentiment.polarity\n",
    "\n",
    "for feature in feature_cols:\n",
    "    df[f'subjectivity_{feature}'] = df[feature].astype('U').apply(getSubjectivity)\n",
    "    df[f'polarity_{feature}'] = df[feature].astype('U').apply(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get the total length of the reviews\n",
    "def get_lengths(df):\n",
    "    '''returns a df with columns with the length of the reviews'''\n",
    "    func = lambda x: len(x) if type(x) == str else 0\n",
    "    df['summary_length'] = df['summary'].apply(func)\n",
    "    df['postives_length'] = df['positives'].apply(func)\n",
    "    df['negatives_length'] = df['negatives'].apply(func)\n",
    "    df['advice_length'] = df['advice_to_mgmt'].apply(func)\n",
    "    df['combined_length'] = df['text_combined'].apply(func)\n",
    "    return df\n",
    "\n",
    "df = get_lengths(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale new features\n",
    "length_cols = [col for col in df.columns if 'length' in col]\n",
    "\n",
    "for col in length_cols:\n",
    "    scaler = MinMaxScaler()\n",
    "    df[col] = scaler.fit_transform(df[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select X\n",
    "X = df.iloc[:, 11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale score features\n",
    "pred_scores_cols = [col for col in X.columns if 'score' in col and not 'reg' in col]\n",
    "\n",
    "for col in pred_scores_cols:\n",
    "    scaler = MinMaxScaler()\n",
    "    X[col] = scaler.fit_transform(X[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression with just the predictions for each model\n",
    "for col in score_cols:\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, df[col])\n",
    "    X[f'reg_{col}'] = model.predict(X)\n",
    "    scaler = MinMaxScaler()\n",
    "    X[f'reg_{col}'] = scaler.fit_transform(X[[f'reg_{col}']])\n",
    "# classification with scores as targets\n",
    "predictions = pd.DataFrame()\n",
    "pred_scores = {}\n",
    "for target in score_cols:\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    y = df[target]\n",
    "    model.fit(X, y)\n",
    "    predictions[target] = model.predict(X)\n",
    "    pred_scores[target] = model.score(X, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(pred_scores)), list(pred_scores.values()), align='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comment for commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
